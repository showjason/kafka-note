# Kafka 性能调优指南

## 概述

Kafka 调优的核心目标是**提升吞吐量**和**降低延时**，这两个目标往往存在权衡关系。

**延时定义**：
- Producer 延时：从消息发送到 Broker 持久化完成的时间间隔
- 端到端延时：从 Producer 发送消息到 Consumer 成功消费的总时长

## 操作系统层面调优

### 文件系统优化
```bash
# 1. 禁用 atime 更新，减少不必要的写操作
mount -o noatime /dev/sda1 /kafka-logs

# 2. 调整系统参数
ulimit -n 1000000                    # 增加文件描述符限制
echo 262144 > /proc/sys/vm/max_map_count  # 避免内存映射限制
```

### 内存管理
- **页缓存**：至少要容纳一个日志段大小（默认 1GB）
- **Swappiness**：设置为 1-10，避免频繁交换
```bash
echo 1 > /proc/sys/vm/swappiness
```

### 磁盘 I/O 优化
- 使用 SSD 存储日志文件
- 分离不同类型的磁盘：操作系统、ZooKeeper、Kafka 日志

## JVM 调优

### 堆内存设置
```bash
# 推荐堆大小：6GB ~ 8GB
-Xms6g -Xmx6g

# 计算公式：Full GC 后存活对象大小 × 1.5~2
# 可用以下命令触发 Full GC 来观察
jmap -histo:live <pid>
```

### GC 收集器选择
```bash
# 推荐使用 G1 收集器
-XX:+UseG1GC
-XX:MaxGCPauseMillis=20
-XX:+PrintAdaptiveSizePolicy  # 帮助排查 Full GC 问题

# 解决大对象问题
-XX:G1HeapRegionSize=32m     # 默认情况下，超过 N/2 的对象为大对象
```

### 常见 GC 问题
- **错误信息**："too many humongous allocations"
- **解决方案**：
  1. 增大堆大小
  2. 调整 G1HeapRegionSize
  3. 优化消息体大小

## Broker 端调优

### 版本兼容性
⚠️ **重要**：保持客户端和 Broker 版本一致以享受 Zero Copy 优化

### 关键参数配置
```properties
# 网络线程数（通常等于 CPU 核数）
num.network.threads=8

# I/O 线程数（通常为 CPU 核数的 2 倍）
num.io.threads=16

# Socket 缓冲区大小
socket.send.buffer.bytes=1048576
socket.receive.buffer.bytes=1048576

# 日志段大小
log.segment.bytes=1073741824

# 副本拉取线程数
num.replica.fetchers=4
```

### 日志段大小调优

`log.segment.bytes` 控制每个日志段文件的大小，需要根据实际场景权衡。

#### 设置原则

**并非越小越好**，需要考虑以下因素：

**设置过小的问题**：
- **文件数量爆炸**：过多的小文件导致文件描述符不足
- **元数据开销**：每个文件都需要维护元数据，增加内存和磁盘开销
- **磁盘碎片**：小文件导致磁盘碎片增加
- **日志清理效率低**：压缩和删除操作需要处理大量小文件

**设置过大的问题**：
- **启动恢复慢**：Broker 重启时需要重建大文件的索引
- **内存压力**：大段文件对应的索引文件占用更多内存
- **日志清理延迟**：只有整个段都过期才能删除，影响数据清理及时性

#### 推荐配置

```properties
# 默认设置，适用于大多数场景
log.segment.bytes=1073741824  # 1GB

# 高吞吐量场景
log.segment.bytes=2147483648  # 2GB

# 低吞吐量或小消息场景
log.segment.bytes=536870912   # 512MB
```

#### 调优考虑因素

**1. 数据保留时间**
```bash
# 如果数据保留7天，段大小应该让日志合理分散到多个段
# 避免单个段包含过多天的数据
```

**2. 消息特征**
- **高吞吐量 + 大消息** → 使用更大的段（1-2GB）
- **低吞吐量 + 小消息** → 使用较小的段（512MB-1GB）

**3. 硬件资源**
- **内存充足** → 可以使用大段（索引占用更多内存）
- **磁盘性能好** → 可以使用大段（顺序写性能更好）

#### 监控命令

```bash
# 查看每个分区的段文件数量
ls -la /kafka-logs/topic-partition-0/ | wc -l

# 监控文件描述符使用情况
lsof -p <broker-pid> | wc -l

# 查看段文件大小分布
du -sh /kafka-logs/topic-*/*.log

# 检查是否超出文件描述符限制
ulimit -n
```

## 应用层调优

### 客户端复用
```java
// ✅ 正确：复用 Producer 实例
static KafkaProducer<String, String> producer = new KafkaProducer<>(props);

// ❌ 错误：每次创建新实例
// KafkaProducer<String, String> producer = new KafkaProducer<>(props);
```

### 资源管理
- Producer 是线程安全的，可以在多线程间共享
- Consumer 不是线程安全的，每个线程需要独立实例
- 及时关闭客户端释放资源（Socket 连接、ByteBuffer 等）

### 多线程消费模式
```java
// 方案一：多 Consumer 实例
ExecutorService executor = Executors.newFixedThreadPool(10);
for (int i = 0; i < 10; i++) {
    executor.submit(new ConsumerWorker());
}

// 方案二：单 Consumer + 多线程处理
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    for (ConsumerRecord<String, String> record : records) {
        executor.submit(() -> processRecord(record));
    }
}
```

## 性能指标调优

### 吞吐量优化原理
通过**批量处理**提升吞吐量：

**示例对比**：

**场景一：单条发送**
- 每条消息发送延时：2ms
- 每秒能发送的消息数：1000ms ÷ 2ms = 500条
- **TPS = 500/s**

**场景二：批量发送**
- 等待时间：8ms（积累消息）
- 发送延时：2ms（网络传输）
- 总延时：8ms + 2ms = 10ms
- 批次大小：1000条消息
- 每秒能完成的批次数：1000ms ÷ 10ms = 100批次
- 每秒发送的消息数：100批次 × 1000条 = 100,000条
- **TPS = 100,000/s**

**关键insight**：虽然单个消息的延时从 2ms 增加到 10ms，但通过批量处理，整体吞吐量提升了 200倍！

### 吞吐量调优参数

| 组件 | 参数 | 推荐值 | 说明 |
|------|------|--------|------|
| **Broker** | `num.replica.fetchers` | CPU 核数 | 增加副本拉取线程 |
| **Broker** | GC 参数 | G1GC | 避免频繁 Full GC |
| **Producer** | `batch.size` | 512KB~1MB | 默认 16KB，适当增大 |
| **Producer** | `linger.ms` | 10~100ms | 等待时间，积累更多消息 |
| **Producer** | `compression.type` | `lz4` 或 `zstd` | 启用压缩减少网络传输 |
| **Producer** | `acks` | `0` 或 `1` | 降低一致性要求 |
| **Producer** | `retries` | `0` | 禁用重试 |
| **Producer** | `buffer.memory` | 128MB+ | 多线程共享时增大 |
| **Consumer** | 多进程/线程 | - | 并行消费提升处理能力 |
| **Consumer** | `fetch.min.bytes` | 1KB+ | 批量拉取消息 |

### 延时调优参数

| 组件 | 参数 | 推荐值 | 说明 |
|------|------|--------|------|
| **Broker** | `num.replica.fetchers` | 适当增加 | 加速副本同步 |
| **Producer** | `linger.ms` | `0` | 立即发送，不等待 |
| **Producer** | `compression.type` | `none` | 禁用压缩减少 CPU 开销 |
| **Producer** | `acks` | `1` | 平衡一致性和性能 |
| **Consumer** | `fetch.min.bytes` | `1` | 立即返回可用数据 |

## 监控与排查

### 关键监控指标
```properties
# 生产者监控
record-send-rate          # 发送速率
record-send-total         # 发送总数
batch-size-avg            # 平均批次大小
compression-rate-avg      # 压缩率

# 消费者监控
records-consumed-rate     # 消费速率
fetch-latency-avg         # 拉取延时
consumer-lag             # 消费延迟

# Broker 监控
MessagesInPerSec         # 消息流入速率
BytesInPerSec           # 字节流入速率
RequestHandlerAvgIdlePercent  # 请求处理器空闲率
```

### 常见性能问题排查

#### 1. 生产者性能低
```bash
# 检查批次大小和延时设置
bin/kafka-run-class.sh kafka.tools.ProducerPerformance \
  --topic test --num-records 1000000 \
  --record-size 1024 --throughput -1 \
  --producer-props bootstrap.servers=localhost:9092
```

#### 2. 消费者性能低
```bash
# 检查消费延迟
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --describe --group my-group
```

#### 3. Broker 性能瓶颈
```bash
# 查看 JVM 内存使用
jstat -gc <broker-pid> 1s

# 查看磁盘 I/O
iostat -x 1
```

## 最佳实践总结

### 🚀 高吞吐量场景
1. 增大 `batch.size` 和 `linger.ms`
2. 启用压缩（lz4/zstd）
3. 设置 `acks=1`
4. 多 Consumer 并行消费

### ⚡ 低延时场景
1. 设置 `linger.ms=0`
2. 禁用压缩
3. 优化网络和磁盘配置
4. 减少 GC 停顿时间

### 🔄 生产环境建议
1. 监控集群关键指标
2. 定期进行性能测试
3. 保持版本一致性
4. 合理规划分区数量
